#!/usr/bin/env python3
"""
Command Injection Vulnerability Checker

This script analyzes Python source code files to identify potential command injection
vulnerabilities by detecting dangerous patterns in subprocess calls and system commands.

Author: Security Analysis Tool
License: MIT
Version: 1.0.0

Usage:
    python command_injection_checker.py file.py
    python command_injection_checker.py directory/ -r
    python command_injection_checker.py file.py --severity high --output report.json
"""

import argparse
import ast
import json
import os
import re
import sys
from pathlib import Path
from typing import List, Dict, Any, Optional, Set
import logging


class CommandInjectionPattern:
    """Represents a pattern that could indicate command injection vulnerability."""
    
    def __init__(self, pattern_type: str, severity: str, description: str, 
                 line: int, column: int, context: str, recommendation: str):
        self.pattern_type = pattern_type
        self.severity = severity
        self.description = description
        self.line = line
        self.column = column
        self.context = context
        self.recommendation = recommendation
    
    def to_dict(self) -> Dict[str, Any]:
        """Convert pattern to dictionary for JSON serialization."""
        return {
            'type': self.pattern_type,
            'severity': self.severity,
            'description': self.description,
            'line': self.line,
            'column': self.column,
            'context': self.context,
            'recommendation': self.recommendation
        }


class CommandInjectionChecker(ast.NodeVisitor):
    """AST visitor to analyze Python code for command injection vulnerabilities."""
    
    # Dangerous functions that can execute system commands
    DANGEROUS_FUNCTIONS = {
        'os.system': 'high',
        'os.popen': 'high',
        'subprocess.call': 'medium',
        'subprocess.run': 'medium',
        'subprocess.Popen': 'medium',
        'subprocess.check_call': 'medium',
        'subprocess.check_output': 'medium',
        'commands.getoutput': 'high',  # Python 2.x
        'commands.getstatusoutput': 'high',  # Python 2.x
        'eval': 'critical',
        'exec': 'critical',
        'compile': 'medium'
    }
    
    # Shell injection indicators
    SHELL_INJECTION_PATTERNS = [
        r'[;&|`$]',  # Shell metacharacters
        r'\$\(',     # Command substitution
        r'`.*`',     # Backtick command substitution
    ]
    
    def __init__(self, source_code: str, filename: str = '<unknown>'):
        """Initialize the checker with source code."""
        self.source_code = source_code
        self.filename = filename
        self.source_lines = source_code.splitlines()
        self.patterns: List[CommandInjectionPattern] = []
        self.imports: Set[str] = set()
    
    def visit_Import(self, node: ast.Import) -> None:
        """Track imports to understand available modules."""
        for alias in node.names:
            self.imports.add(alias.name)
        self.generic_visit(node)
    
    def visit_ImportFrom(self, node: ast.ImportFrom) -> None:
        """Track from imports to understand available functions."""
        if node.module:
            for alias in node.names:
                self.imports.add(f"{node.module}.{alias.name}")
        self.generic_visit(node)
    
    def visit_Call(self, node: ast.Call) -> None:
        """Analyze function calls for potential command injection."""
        func_name = self._get_function_name(node.func)
        
        if func_name in self.DANGEROUS_FUNCTIONS:
            severity = self.DANGEROUS_FUNCTIONS[func_name]
            self._analyze_dangerous_call(node, func_name, severity)
        
        # Check for shell=True parameter in subprocess calls
        if func_name.startswith('subprocess.'):
            self._check_shell_parameter(node, func_name)
        
        self.generic_visit(node)
    
    def _get_function_name(self, node: ast.AST) -> str:
        """Extract function name from AST node."""
        if isinstance(node, ast.Name):
            return node.id
        elif isinstance(node, ast.Attribute):
            value_name = self._get_function_name(node.value)
            return f"{value_name}.{node.attr}"
        return ""
    
    def _analyze_dangerous_call(self, node: ast.Call, func_name: str, severity: str) -> None:
        """Analyze a potentially dangerous function call."""
        context = self._get_source_context(node)
        
        # Check if the command contains user input or variables
        has_user_input = False
        has_string_formatting = False
        has_concatenation = False
        
        for arg in node.args:
            if self._contains_user_input_pattern(arg):
                has_user_input = True
            if self._contains_string_formatting(arg):
                has_string_formatting = True
            if self._contains_string_concatenation(arg):
                has_concatenation = True
        
        # Analyze string literals for shell metacharacters
        for arg in node.args:
            if isinstance(arg, ast.Str):
                self._check_shell_metacharacters(arg.s, node, context)
        
        # Create pattern based on analysis
        if has_user_input or has_string_formatting or has_concatenation:
            self.patterns.append(CommandInjectionPattern(
                pattern_type='dangerous_call_with_input',
                severity='critical' if severity == 'high' else 'high',
                description=f"Potentially unsafe use of {func_name} with user input or variables",
                line=node.lineno,
                column=node.col_offset,
                context=context,
                recommendation=f"Validate and sanitize input before passing to {func_name}. "
                              f"Consider using subprocess with shell=False and argument lists."
            ))
        else:
            self.patterns.append(CommandInjectionPattern(
                pattern_type='dangerous_call',
                severity=severity,
                description=f"Use of potentially dangerous function: {func_name}",
                line=node.lineno,
                column=node.col_offset,
                context=context,
                recommendation=f"Review use of {func_name}. Consider safer alternatives if possible."
            ))
    
    def _check_shell_parameter(self, node: ast.Call, func_name: str) -> None:
        """Check for shell=True parameter in subprocess calls."""
        for keyword in node.keywords:
            if keyword.arg == 'shell' and isinstance(keyword.value, ast.Constant):
                if keyword.value.value is True:
                    context = self._get_source_context(node)
                    self.patterns.append(CommandInjectionPattern(
                        pattern_type='shell_true',
                        severity='high',
                        description=f"{func_name} called with shell=True",
                        line=node.lineno,
                        column=node.col_offset,
                        context=context,
                        recommendation="Avoid shell=True when possible. Use argument lists instead "
                                      "of shell commands to prevent injection attacks."
                    ))
    
    def _contains_user_input_pattern(self, node: ast.AST) -> bool:
        """Check if node contains patterns suggesting user input."""
        user_input_indicators = [
            'input', 'raw_input', 'sys.argv', 'request.', 'form.',
            'args.', 'params.', 'query.', '.get(', '.POST', '.GET'
        ]
        
        source = ast.unparse(node) if hasattr(ast, 'unparse') else str(node)
        return any(indicator in source for indicator in user_input_indicators)
    
    def _contains_string_formatting(self, node: ast.AST) -> bool:
        """Check if node contains string formatting operations."""
        return (isinstance(node, ast.BinOp) and isinstance(node.op, ast.Mod) or
                isinstance(node, ast.JoinedStr) or  # f-strings
                isinstance(node, ast.Call) and 
                isinstance(node.func, ast.Attribute) and 
                node.func.attr == 'format')
    
    def _contains_string_concatenation(self, node: ast.AST) -> bool:
        """Check if node contains string concatenation."""
        return (isinstance(node, ast.BinOp) and isinstance(node.op, ast.Add))
    
    def _check_shell_metacharacters(self, string_value: str, node: ast.AST, context: str) -> None:
        """Check string literals for shell metacharacters."""
        for pattern in self.SHELL_INJECTION_PATTERNS:
            if re.search(pattern, string_value):
                self.patterns.append(CommandInjectionPattern(
                    pattern_type='shell_metacharacters',
                    severity='medium',
                    description=f"String contains shell metacharacters: {pattern}",
                    line=node.lineno,
                    column=node.col_offset,
                    context=context,
                    recommendation="Avoid shell metacharacters in commands. "
                                  "Use parameterized commands or proper escaping."
                ))
                break
    
    def _get_source_context(self, node: ast.AST, context_lines: int = 2) -> str:
        """Get source code context around a node."""
        start_line = max(0, node.lineno - context_lines - 1)
        end_line = min(len(self.source_lines), node.lineno + context_lines)
        
        context_lines_list = []
        for i in range(start_line, end_line):
            line_num = i + 1
            marker = ">>> " if line_num == node.lineno else "    "
            context_lines_list.append(f"{marker}{line_num:3d}: {self.source_lines[i]}")
        
        return "\n".join(context_lines_list)


def analyze_file(file_path: Path) -> List[CommandInjectionPattern]:
    """Analyze a single Python file for command injection vulnerabilities."""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            source_code = f.read()
        
        # Parse the AST
        tree = ast.parse(source_code, filename=str(file_path))
        
        # Run the checker
        checker = CommandInjectionChecker(source_code, str(file_path))
        checker.visit(tree)
        
        return checker.patterns
    
    except SyntaxError as e:
        logging.warning(f"Syntax error in {file_path}: {e}")
        return []
    except Exception as e:
        logging.error(f"Error analyzing {file_path}: {e}")
        return []


def analyze_directory(directory_path: Path, recursive: bool = False) -> Dict[str, List[CommandInjectionPattern]]:
    """Analyze all Python files in a directory."""
    results = {}
    
    if recursive:
        pattern = "**/*.py"
    else:
        pattern = "*.py"
    
    for file_path in directory_path.glob(pattern):
        if file_path.is_file():
            patterns = analyze_file(file_path)
            if patterns:
                results[str(file_path)] = patterns
    
    return results


def filter_by_severity(patterns: List[CommandInjectionPattern], min_severity: str) -> List[CommandInjectionPattern]:
    """Filter patterns by minimum severity level."""
    severity_levels = {'low': 0, 'medium': 1, 'high': 2, 'critical': 3}
    min_level = severity_levels.get(min_severity.lower(), 0)
    
    return [p for p in patterns if severity_levels.get(p.severity.lower(), 0) >= min_level]


def format_console_output(results: Dict[str, List[CommandInjectionPattern]], min_severity: str = 'low') -> str:
    """Format results for console output."""
    output_lines = []
    total_issues = 0
    
    output_lines.append("=" * 60)
    output_lines.append("COMMAND INJECTION VULNERABILITY ANALYSIS")
    output_lines.append("=" * 60)
    
    for file_path, patterns in results.items():
        filtered_patterns = filter_by_severity(patterns, min_severity)
        if not filtered_patterns:
            continue
        
        output_lines.append(f"\nFile: {file_path}")
        output_lines.append("-" * 40)
        
        for pattern in filtered_patterns:
            total_issues += 1
            output_lines.append(f"\n[{pattern.severity.upper()}] {pattern.description}")
            output_lines.append(f"Location: Line {pattern.line}, Column {pattern.column}")
            output_lines.append(f"Type: {pattern.pattern_type}")
            output_lines.append(f"Recommendation: {pattern.recommendation}")
            output_lines.append(f"\nContext:")
            output_lines.append(pattern.context)
            output_lines.append("")
    
    output_lines.append("=" * 60)
    output_lines.append(f"Total issues found: {total_issues}")
    output_lines.append("=" * 60)
    
    return "\n".join(output_lines)


def save_json_report(results: Dict[str, List[CommandInjectionPattern]], output_path: Path) -> None:
    """Save results to JSON file."""
    json_results = {}
    for file_path, patterns in results.items():
        json_results[file_path] = [pattern.to_dict() for pattern in patterns]
    
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(json_results, f, indent=2, ensure_ascii=False)


def main():
    """Main function to handle command line arguments and execute analysis."""
    parser = argparse.ArgumentParser(
        description="Analyze Python code for command injection vulnerabilities",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  python command_injection_checker.py script.py
  python command_injection_checker.py /path/to/project --recursive
  python command_injection_checker.py app.py --severity high --output report.json
  python command_injection_checker.py . -r --severity medium
        """
    )
    
    parser.add_argument(
        'target',
        help='Python file or directory to analyze'
    )
    
    parser.add_argument(
        '-r', '--recursive',
        action='store_true',
        help='Recursively analyze subdirectories'
    )
    
    parser.add_argument(
        '--severity',
        choices=['low', 'medium', 'high', 'critical'],
        default='low',
        help='Minimum severity level to report (default: low)'
    )
    
    parser.add_argument(
        '-o', '--output',
        type=Path,
        help='Save results to JSON file'
    )
    
    parser.add_argument(
        '-v', '--verbose',
        action='store_true',
        help='Enable verbose logging'
    )
    
    args = parser.parse_args()
    
    # Configure logging
    log_level = logging.DEBUG if args.verbose else logging.INFO
    logging.basicConfig(level=log_level, format='%(levelname)s: %(message)s')
    
    # Validate target path
    target_path = Path(args.target)
    if not target_path.exists():
        print(f"Error: Path '{target_path}' does not exist", file=sys.stderr)
        sys.exit(1)
    
    # Analyze target
    try:
        if target_path.is_file():
            if not target_path.suffix == '.py':
                print(f"Warning: '{target_path}' is not a Python file", file=sys.stderr)
            
            patterns = analyze_file(target_path)
            results = {str(target_path): patterns} if patterns else {}
        
        elif target_path.is_dir():
            results = analyze_directory(target_path, args.recursive)
        
        else:
            print(f"Error: '{target_path}' is neither a file nor directory", file=sys.stderr)
            sys.exit(1)
        
        # Filter and output results
        if not results:
            print("No command injection vulnerabilities detected.")
            sys.exit(0)
        
        # Save to JSON if requested
        if args.output:
            save_json_report(results, args.output)
            print(f"Results saved to {args.output}")
        
        # Print console output
        console_output = format_console_output(results, args.severity)
        print(console_output)
        
        # Set exit code based on findings
        total_critical = sum(1 for patterns in results.values() 
                           for pattern in patterns 
                           if pattern.severity == 'critical')
        
        if total_critical > 0:
            sys.exit(2)  # Critical issues found
        else:
            sys.exit(1)  # Non-critical issues found
    
    except KeyboardInterrupt:
        print("\nAnalysis interrupted by user", file=sys.stderr)
        sys.exit(130)
    except Exception as e:
        logging.error(f"Unexpected error: {e}")
        sys.exit(1)


if __name__ == '__main__':
    main()

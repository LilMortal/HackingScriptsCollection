#!/usr/bin/env python3
"""
System Monitor and Log Analysis Tool

A comprehensive tool for monitoring system resources and analyzing log files.
Provides real-time system statistics and log file analysis with filtering,
pattern matching, and alert detection capabilities.

Usage Examples:
    # Monitor system resources in real-time
    python system_monitor.py --monitor --interval 5

    # Analyze a log file for errors
    python system_monitor.py --analyze /var/log/syslog --filter ERROR

    # Monitor system and save to file
    python system_monitor.py --monitor --output system_stats.log

    # Analyze log with custom pattern
    python system_monitor.py --analyze app.log --pattern "failed|error|exception"

Author: System Administrator
License: MIT
"""

import argparse
import datetime
import json
import os
import psutil
import re
import signal
import sys
import time
from collections import Counter, defaultdict
from pathlib import Path
from typing import Dict, List, Optional, Tuple


class SystemMonitor:
    """Main class for system monitoring and log analysis functionality."""
    
    def __init__(self, output_file: Optional[str] = None):
        """
        Initialize the SystemMonitor.
        
        Args:
            output_file: Optional file path to save monitoring output
        """
        self.output_file = output_file
        self.monitoring = False
        self.start_time = datetime.datetime.now()
        
        # Setup signal handlers for graceful shutdown
        signal.signal(signal.SIGINT, self._signal_handler)
        signal.signal(signal.SIGTERM, self._signal_handler)
    
    def _signal_handler(self, signum, frame):
        """Handle shutdown signals gracefully."""
        print("\n\nShutdown signal received. Stopping monitoring...")
        self.monitoring = False
        sys.exit(0)
    
    def get_system_stats(self) -> Dict:
        """
        Collect comprehensive system statistics.
        
        Returns:
            Dictionary containing system statistics
        """
        try:
            # CPU information
            cpu_percent = psutil.cpu_percent(interval=1)
            cpu_count = psutil.cpu_count()
            cpu_freq = psutil.cpu_freq()
            
            # Memory information
            memory = psutil.virtual_memory()
            swap = psutil.swap_memory()
            
            # Disk information
            disk_usage = psutil.disk_usage('/')
            disk_io = psutil.disk_io_counters()
            
            # Network information
            network_io = psutil.net_io_counters()
            
            # Process information
            processes = len(psutil.pids())
            
            # System uptime
            boot_time = psutil.boot_time()
            uptime = time.time() - boot_time
            
            # Load average (Unix-like systems only)
            load_avg = None
            if hasattr(os, 'getloadavg'):
                load_avg = os.getloadavg()
            
            stats = {
                'timestamp': datetime.datetime.now().isoformat(),
                'cpu': {
                    'percent': cpu_percent,
                    'count': cpu_count,
                    'frequency': cpu_freq._asdict() if cpu_freq else None
                },
                'memory': {
                    'total': memory.total,
                    'available': memory.available,
                    'percent': memory.percent,
                    'used': memory.used,
                    'free': memory.free
                },
                'swap': {
                    'total': swap.total,
                    'used': swap.used,
                    'free': swap.free,
                    'percent': swap.percent
                },
                'disk': {
                    'total': disk_usage.total,
                    'used': disk_usage.used,
                    'free': disk_usage.free,
                    'percent': disk_usage.percent,
                    'io': disk_io._asdict() if disk_io else None
                },
                'network': {
                    'bytes_sent': network_io.bytes_sent,
                    'bytes_recv': network_io.bytes_recv,
                    'packets_sent': network_io.packets_sent,
                    'packets_recv': network_io.packets_recv
                },
                'system': {
                    'processes': processes,
                    'uptime_seconds': uptime,
                    'load_average': load_avg
                }
            }
            
            return stats
            
        except Exception as e:
            print(f"Error collecting system stats: {e}")
            return {}
    
    def format_bytes(self, bytes_value: int) -> str:
        """
        Convert bytes to human-readable format.
        
        Args:
            bytes_value: Number of bytes
            
        Returns:
            Human-readable string representation
        """
        for unit in ['B', 'KB', 'MB', 'GB', 'TB']:
            if bytes_value < 1024.0:
                return f"{bytes_value:.2f} {unit}"
            bytes_value /= 1024.0
        return f"{bytes_value:.2f} PB"
    
    def format_uptime(self, seconds: float) -> str:
        """
        Convert seconds to human-readable uptime format.
        
        Args:
            seconds: Uptime in seconds
            
        Returns:
            Human-readable uptime string
        """
        days = int(seconds // 86400)
        hours = int((seconds % 86400) // 3600)
        minutes = int((seconds % 3600) // 60)
        return f"{days}d {hours}h {minutes}m"
    
    def display_system_stats(self, stats: Dict):
        """
        Display system statistics in a formatted way.
        
        Args:
            stats: Dictionary containing system statistics
        """
        if not stats:
            return
        
        print(f"\n{'='*60}")
        print(f"System Monitor - {stats['timestamp']}")
        print(f"{'='*60}")
        
        # CPU Information
        cpu = stats['cpu']
        print(f"\nCPU:")
        print(f"  Usage: {cpu['percent']:.1f}%")
        print(f"  Cores: {cpu['count']}")
        if cpu['frequency']:
            print(f"  Frequency: {cpu['frequency']['current']:.0f} MHz")
        
        # Memory Information
        memory = stats['memory']
        print(f"\nMemory:")
        print(f"  Total: {self.format_bytes(memory['total'])}")
        print(f"  Used: {self.format_bytes(memory['used'])} ({memory['percent']:.1f}%)")
        print(f"  Available: {self.format_bytes(memory['available'])}")
        
        # Swap Information
        swap = stats['swap']
        if swap['total'] > 0:
            print(f"\nSwap:")
            print(f"  Total: {self.format_bytes(swap['total'])}")
            print(f"  Used: {self.format_bytes(swap['used'])} ({swap['percent']:.1f}%)")
        
        # Disk Information
        disk = stats['disk']
        print(f"\nDisk (/):")
        print(f"  Total: {self.format_bytes(disk['total'])}")
        print(f"  Used: {self.format_bytes(disk['used'])} ({disk['percent']:.1f}%)")
        print(f"  Free: {self.format_bytes(disk['free'])}")
        
        # Network Information
        network = stats['network']
        print(f"\nNetwork:")
        print(f"  Bytes Sent: {self.format_bytes(network['bytes_sent'])}")
        print(f"  Bytes Received: {self.format_bytes(network['bytes_recv'])}")
        print(f"  Packets Sent: {network['packets_sent']:,}")
        print(f"  Packets Received: {network['packets_recv']:,}")
        
        # System Information
        system = stats['system']
        print(f"\nSystem:")
        print(f"  Processes: {system['processes']}")
        print(f"  Uptime: {self.format_uptime(system['uptime_seconds'])}")
        if system['load_average']:
            load_avg = system['load_average']
            print(f"  Load Average: {load_avg[0]:.2f}, {load_avg[1]:.2f}, {load_avg[2]:.2f}")
    
    def save_stats(self, stats: Dict):
        """
        Save statistics to output file.
        
        Args:
            stats: Dictionary containing system statistics
        """
        if not self.output_file:
            return
        
        try:
            with open(self.output_file, 'a') as f:
                f.write(json.dumps(stats) + '\n')
        except Exception as e:
            print(f"Error saving stats to file: {e}")
    
    def monitor_system(self, interval: int = 5):
        """
        Continuously monitor system resources.
        
        Args:
            interval: Time between monitoring cycles in seconds
        """
        print(f"Starting system monitoring (interval: {interval}s)")
        print("Press Ctrl+C to stop monitoring")
        
        self.monitoring = True
        
        try:
            while self.monitoring:
                stats = self.get_system_stats()
                if stats:
                    self.display_system_stats(stats)
                    self.save_stats(stats)
                
                time.sleep(interval)
                
        except KeyboardInterrupt:
            print("\nMonitoring stopped by user")
        except Exception as e:
            print(f"Error during monitoring: {e}")


class LogAnalyzer:
    """Class for analyzing log files and detecting patterns."""
    
    def __init__(self):
        """Initialize the LogAnalyzer."""
        self.log_patterns = {
            'error': re.compile(r'error|failed|failure|exception|critical', re.IGNORECASE),
            'warning': re.compile(r'warning|warn', re.IGNORECASE),
            'info': re.compile(r'info|information', re.IGNORECASE),
            'debug': re.compile(r'debug', re.IGNORECASE)
        }
    
    def analyze_log_file(self, file_path: str, filter_text: Optional[str] = None, 
                        pattern: Optional[str] = None, tail_lines: Optional[int] = None) -> Dict:
        """
        Analyze a log file for patterns and statistics.
        
        Args:
            file_path: Path to the log file
            filter_text: Filter lines containing this text
            pattern: Custom regex pattern to search for
            tail_lines: Only analyze the last N lines
            
        Returns:
            Dictionary containing analysis results
        """
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"Log file not found: {file_path}")
        
        try:
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                lines = f.readlines()
            
            # Get only the last N lines if specified
            if tail_lines:
                lines = lines[-tail_lines:]
            
            total_lines = len(lines)
            matched_lines = []
            level_counts = Counter()
            pattern_matches = []
            timestamps = []
            
            # Custom pattern compilation
            custom_pattern = None
            if pattern:
                try:
                    custom_pattern = re.compile(pattern, re.IGNORECASE)
                except re.error as e:
                    print(f"Invalid regex pattern: {e}")
                    return {}
            
            # Process each line
            for line_num, line in enumerate(lines, 1):
                line = line.strip()
                if not line:
                    continue
                
                # Apply text filter
                if filter_text and filter_text.lower() not in line.lower():
                    continue
                
                # Apply custom pattern
                if custom_pattern and not custom_pattern.search(line):
                    continue
                
                matched_lines.append((line_num, line))
                
                # Check for log levels
                for level, regex in self.log_patterns.items():
                    if regex.search(line):
                        level_counts[level] += 1
                        break
                
                # Extract timestamps (basic attempt)
                timestamp_match = re.search(r'\d{4}-\d{2}-\d{2}[\s\T]\d{2}:\d{2}:\d{2}', line)
                if timestamp_match:
                    timestamps.append(timestamp_match.group())
            
            # Generate analysis results
            analysis = {
                'file_path': file_path,
                'file_size': os.path.getsize(file_path),
                'total_lines': total_lines,
                'matched_lines': len(matched_lines),
                'level_counts': dict(level_counts),
                'timestamps_found': len(timestamps),
                'analysis_time': datetime.datetime.now().isoformat()
            }
            
            return analysis, matched_lines
            
        except Exception as e:
            print(f"Error analyzing log file: {e}")
            return {}, []
    
    def display_analysis_results(self, analysis: Dict, matched_lines: List[Tuple[int, str]], 
                               show_lines: bool = True, max_lines: int = 100):
        """
        Display log analysis results.
        
        Args:
            analysis: Analysis results dictionary
            matched_lines: List of matched lines with line numbers
            show_lines: Whether to display matched lines
            max_lines: Maximum number of lines to display
        """
        print(f"\n{'='*60}")
        print(f"Log Analysis Results")
        print(f"{'='*60}")
        
        print(f"\nFile: {analysis['file_path']}")
        print(f"File Size: {self.format_bytes(analysis['file_size'])}")
        print(f"Total Lines: {analysis['total_lines']:,}")
        print(f"Matched Lines: {analysis['matched_lines']:,}")
        print(f"Analysis Time: {analysis['analysis_time']}")
        
        # Display level counts
        if analysis['level_counts']:
            print(f"\nLog Level Distribution:")
            for level, count in analysis['level_counts'].items():
                percentage = (count / analysis['matched_lines']) * 100 if analysis['matched_lines'] > 0 else 0
                print(f"  {level.upper()}: {count:,} ({percentage:.1f}%)")
        
        # Display matched lines
        if show_lines and matched_lines:
            print(f"\nMatched Lines (showing first {min(max_lines, len(matched_lines))}):")
            print("-" * 60)
            
            for i, (line_num, line) in enumerate(matched_lines[:max_lines]):
                print(f"{line_num:6d}: {line}")
            
            if len(matched_lines) > max_lines:
                print(f"... and {len(matched_lines) - max_lines} more lines")
    
    def format_bytes(self, bytes_value: int) -> str:
        """Convert bytes to human-readable format."""
        for unit in ['B', 'KB', 'MB', 'GB', 'TB']:
            if bytes_value < 1024.0:
                return f"{bytes_value:.2f} {unit}"
            bytes_value /= 1024.0
        return f"{bytes_value:.2f} PB"


def main():
    """Main function to handle command-line arguments and execute appropriate functionality."""
    parser = argparse.ArgumentParser(
        description="System Monitor and Log Analysis Tool",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  %(prog)s --monitor --interval 10
  %(prog)s --analyze /var/log/syslog --filter ERROR
  %(prog)s --monitor --output system_stats.log
  %(prog)s --analyze app.log --pattern "failed|error" --tail 1000
        """
    )
    
    # Main operation modes
    group = parser.add_mutually_exclusive_group(required=True)
    group.add_argument('--monitor', action='store_true',
                      help='Monitor system resources in real-time')
    group.add_argument('--analyze', type=str, metavar='FILE',
                      help='Analyze log file')
    
    # Monitoring options
    parser.add_argument('--interval', type=int, default=5, metavar='SECONDS',
                       help='Monitoring interval in seconds (default: 5)')
    parser.add_argument('--output', type=str, metavar='FILE',
                       help='Output file for monitoring data (JSON format)')
    
    # Log analysis options
    parser.add_argument('--filter', type=str, metavar='TEXT',
                       help='Filter log lines containing specified text')
    parser.add_argument('--pattern', type=str, metavar='REGEX',
                       help='Custom regex pattern to search for')
    parser.add_argument('--tail', type=int, metavar='LINES',
                       help='Only analyze the last N lines of the log file')
    parser.add_argument('--no-lines', action='store_true',
                       help='Don\'t display matched log lines')
    parser.add_argument('--max-lines', type=int, default=100, metavar='N',
                       help='Maximum number of lines to display (default: 100)')
    
    args = parser.parse_args()
    
    try:
        if args.monitor:
            # System monitoring mode
            if args.interval < 1:
                print("Error: Monitoring interval must be at least 1 second")
                return 1
            
            monitor = SystemMonitor(output_file=args.output)
            monitor.monitor_system(interval=args.interval)
        
        elif args.analyze:
            # Log analysis mode
            analyzer = LogAnalyzer()
            analysis, matched_lines = analyzer.analyze_log_file(
                file_path=args.analyze,
                filter_text=args.filter,
                pattern=args.pattern,
                tail_lines=args.tail
            )
            
            if analysis:
                analyzer.display_analysis_results(
                    analysis=analysis,
                    matched_lines=matched_lines,
                    show_lines=not args.no_lines,
                    max_lines=args.max_lines
                )
            else:
                print("Failed to analyze log file")
                return 1
    
    except KeyboardInterrupt:
        print("\nOperation cancelled by user")
        return 0
    except Exception as e:
        print(f"Error: {e}")
        return 1
    
    return 0


if __name__ == "__main__":
    sys.exit(main())